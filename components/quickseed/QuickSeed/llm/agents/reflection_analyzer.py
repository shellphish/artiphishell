#!/usr/bin/env python3
import logging
import os
from pathlib import Path
from typing import List


from agentlib import (
    AgentPlanStep,
    SaveLoadObject,
    Field,
    AgentPlanStepAttempt,
)
from .base_agent import BaseAgent


_l = logging.getLogger(__name__)


class RaOutput(SaveLoadObject):
    """
    This object describes a script that will generate inputs that invoke reflection call
    - key1: value_description.
    """

    generate_seed_script: str = Field(
        default="No", description="the script generated by the previous step", Optional=False
    )
    seed_structure: str = Field(
        default="No", description="explain the seed structure and break it down for me", Optional=True
    )
    source_func: str = Field(
        default="No",
        description="output the methods that the reflection call is going to invoke", Optional=True
    )




class ReflectionAnalyzerAgent(BaseAgent):
    """
    This agent will follow the steps above.
    """
    current_dir = os.path.dirname(os.path.abspath(__file__))
    prompt_dir = os.path.join(current_dir, "prompts")
    _l.debug(f"llm folder is {prompt_dir}")
    system_prompt = os.path.join(prompt_dir, "ra.system.j2")
    user_prompt = os.path.join(prompt_dir, "generic.user.j2")

    __SYSTEM_PROMPT_TEMPLATE__ = system_prompt
    __USER_PROMPT_TEMPLATE__ = user_prompt
    __LLM_ARGS__ = {"temperature": 0,
                    "max_tokens": 8192}

    broken_call_chain: str
    function_names: List[str]
    fall_back_python_script: Path

    def get_step_input_vars(self, step: AgentPlanStep) -> dict:
        # Template variables for the prompts
        return dict(
            **super().get_step_input_vars(step),
            broken_call_chain=self.broken_call_chain,
            function_names=self.function_names,
            target_method=self.function_names[-1]
        )


    def get_available_tools(self):
        return [
            # Import some predefined tools
            # tools.run_shell_command,
            # tools.give_up_on_task,
            # Here is our own tool
        ]

    def validate_step_result(
            self,
            step: AgentPlanStep,
            attempt: AgentPlanStepAttempt,
            result
    ) -> bool:
        # Here we can perform validation on the result of the step
        # If we return False, the agent will retry the step with our feedback

        # This first example will take the llm output and pass it into some other part
        # which uses that output and gives CriticFeedback
        if step.name == 'write_python_script':
            _l.debug(f"the script is {result}")
            assert (isinstance(result, str))
            res = self.validate_gen_scripts_result(result)
            if res.success:
                return True
            attempt.critic_review = res
            return False
        return super().validate_step_result(step, attempt, result)