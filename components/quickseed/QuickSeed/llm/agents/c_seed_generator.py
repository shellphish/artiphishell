#!/usr/bin/env python3
import logging
import os
import random
import string
import subprocess
import tempfile
from pathlib import Path
from typing import Optional, Any, List, Tuple, Union

import yaml
from agentlib import (
    PlanExecutor,
    AgentResponse,
    AgentPlan,
    AgentPlanStep,
    SaveLoadObject,
    Field,
    ObjectParser,
    AgentPlanStepAttempt,
    CriticReview,
    enable_event_dumping,
    set_global_budget_limit
)

_l = logging.getLogger(__name__)


class HaOutput(SaveLoadObject):
    """
    This object describes an input seed that will trigger the sink function (last function) from harness
    - key1: value_description.
    """

    seed: Any = Field(
        default="No", description="the input seed that will trigger the harness"
    )
    bytes_seed: str = Field(
        default="No", description="the script generated by the previous step"
    )
    seed_structure: str = Field(
        default="No", description="explain the seed structure and break it down for me"
    )
    source_func: str = Field(
        default="No",
        description="output the function that this harness is going to trigger",
    )


def generate_plan(model):
    # Create a plan for the agent to follow.
    current_dir = os.path.dirname(os.path.abspath(__file__))
    _l.debug(f"current_dir is {current_dir}")
    prompt_dir = os.path.join(current_dir, "prompts")
    plan_dir = os.path.join(current_dir, "plans")
    # _l.debug(f"files in dirs are {os.listdir(prompt_dir)}")
    # _l.debug(f"files in dirs are {os.listdir(plan_dir)}")
    plan_file = os.path.join(current_dir, "plans/c_seed_generator_plans.yaml")
    with open(plan_file, 'r') as f:
        steps_yaml: List = yaml.safe_load(f).values()
        chosen_steps = steps_yaml
    _l.debug(f"chosen_steps is {chosen_steps}")
    assert chosen_steps is not None
    steps = list(map(
        lambda s: AgentPlanStep(llm_model=model,
                                name=s['name'],
                                description=s['description']),
        chosen_steps))
    # this would save it in json format.
    # hack - sometimes gpt changes the keys or adds spaces to json keynames. below is example of how to handle that
    # 'The output MUST be in the following JSON format and use the same keys OR I WILL DIE.\n' +
    # '{"equivalent": "Answer in Yes or No", "details": details_of_changes}'
    steps.append(AgentPlanStep(llm_model=model,
                               name="some_final_step",
                               description="Save data in a text format. ",
                               output_parser=ObjectParser(HaOutput, use_fallback=True)))
    plan = AgentPlan(steps=steps)
    return plan.save_copy()


class CSeedGenerator(PlanExecutor[str, str]):
    """
    This agent will follow the steps above.
    """
    current_dir = os.path.dirname(os.path.abspath(__file__))
    prompt_dir = os.path.join(current_dir, "prompts")
    _l.debug(f"llm folder is {prompt_dir}")
    system_prompt = os.path.join(prompt_dir, "csg.system.j2")
    user_prompt = os.path.join(prompt_dir, "generic.user.j2")

    __SYSTEM_PROMPT_TEMPLATE__ = system_prompt
    __USER_PROMPT_TEMPLATE__ = user_prompt
    __LLM_ARGS__ = {"temperature": 0}

    harness_code: Optional[str]
    source_and_traces: str
    commit_change: Optional[str]

    # jazzer_sanitizer_description: List
    # pois_reason: Optional[str]

    def extract_step_attempt_context(
            self, step: AgentPlanStep, result: AgentResponse
    ) -> str:
        """
        Disable step summarization, and just use the last result from the LLM
        """
        return step.attempts[-1].result

    def extract_final_results(self) -> str:
        """
        Disable final output summarization and just use the last result from the LLM
        """
        steps = self.plan.get_past_steps()
        return steps[-1].attempts[-1].result

    def get_step_input_vars(self, step: AgentPlanStep) -> dict:
        # Template variables for the prompts
        return dict(
            **super().get_step_input_vars(step),
            hello="world",
            harness_code=self.harness_code,
            source_and_traces=self.source_and_traces,
            commit_change=self.commit_change,
        )

    # def on_step_success(self, step: AgentPlanStep, result):
    #     """
    #     This is just an example of how you could conditionally skip a step if you wanted.
    #     """
    #     if step.name == "should_we_skip_the_step":
    #         assert isinstance(result, str)
    #         if "true" in result.lower():
    #             # Skip over the next step
    #             self.plan.current_step += 1

    #     return super().on_step_success(step, result)

    def validate_gen_scripts_result(self, result: str) -> CriticReview:
        """
        Validate the result of the generate_script step.
        """
        if "No" in result:
            return CriticReview(success=False, feedback="No seed is generated").save_copy()
        return CriticReview(success=True, feedback="").save_copy()

    def validate_step_result(
            self,
            step: AgentPlanStep,
            attempt: AgentPlanStepAttempt,
            result
    ) -> bool:
        # Here we can perform validation on the result of the step
        # If we return False, the agent will retry the step with our feedback

        # This first example will take the llm output and pass it into some other part
        # which uses that output and gives CriticFeedback
        if step.name == 'review_script':
            _l.debug(f"the script is {result}")
            assert (isinstance(result, str))
            res = self.validate_gen_scripts_result(result)
            if res.success:
                return True
            attempt.critic_review = res
            return False

        return super().validate_step_result(step, attempt, result)


def c_seed_generator_agent(
        agent_path,
        harness_code: str,
        source_and_traces: str,
        model: str,
        commit_changes: Optional[str] = None,
        # pois_reason: str = None
) -> Tuple[Optional[Path], Optional[Path]]:
    """
       Generates and executes a harness agent to produce interesting seeds.

       Args:
           agent_path (str): Path to save the agent's state.
           harness_code (str): The code for the harness.
           source_and_traces (str): Source code and trace information.
           model (str): The model to use for the agent.
           commit_changes (str): The changes to commit to the source code.

       Returns:
           Tuple[Optional[Path], Optional[Path]]: Paths to the generated seed script and seed file, or None if generation failed.
       """
    # enable_event_dumping('/tmp/quickseed-agentlib-cost') # somewhere in shared
    # set_global_budget_limit(
    #     price_in_dollars=5,
    #     exit_on_over_budget=True
    # )
    plan = generate_plan(model)
    _l.debug(f"plan is saved at {agent_path}")
    agent: CSeedGenerator = CSeedGenerator.reload_id_from_file_or_new(
        agent_path,
        goal="generate interesting seeds",
        plan=plan,
        harness_code=harness_code,
        source_and_traces=source_and_traces,
        commit_changes=commit_changes,
    )

    # agent.use_web_logging_config()

    agent.warn("========== Agents plan ==========\n")
    _l.debug(agent)
    _l.debug(agent.plan)

    agent.warn("========== Running agent ==========\n")

    res = agent.invoke()
    _l.debug(f"res is {res}")
    script = res.bytes_seed.split("\n")
    if "```" in res.bytes_seed:
        script = script[1:-1]
    _l.debug(f"The script dumping in gen_seed.py is {script}")
    if "No" in script[0]:
        return None, None
    script = "\n".join(script)

    tmpdir = Path(tempfile.mkdtemp())
    _l.info(f"the files is saved to {tmpdir}")
    seed_gen_scripts = tmpdir / "gen_seed.py"
    seed = tmpdir / "output.bin"
    with open(seed_gen_scripts, "w") as f:
        f.write(script)
    try:
        p = subprocess.run(["python3", seed_gen_scripts], capture_output=True, text=True, errors="ignore", cwd=tmpdir)
        if p.returncode != 0:
            _l.debug(f"{p.stderr}")
    except Exception as e:
        _l.error(f"error occured {e} when generating seeds")
        return None, None
    if not seed.exists():
        _l.warning("No output.bin file generated")
        return None, None
    _l.debug(f"seed is {seed} seed_gen_script is {seed_gen_scripts}")
    return seed_gen_scripts, seed
