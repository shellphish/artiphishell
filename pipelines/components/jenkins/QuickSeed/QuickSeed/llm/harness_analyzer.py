#!/usr/bin/env python3
import os, sys, json, random, shutil, string, subprocess, tempfile, yaml
from typing import Dict, Optional, Any, List
from pathlib import Path
import logging
_l = logging.getLogger(__name__)

import QuickSeed
from typing import Union, Dict, Any
from QuickSeed.utils import WorkDirContext
from QuickSeed.parser import TaintParser
from QuickSeed.data import Program, Node, Edge, Graph
import agentlib
from agentlib import (
    Agent,
    PlanExecutor,
    AgentResponse,
    AgentPlan,
    AgentPlanStep,
    AgentPlanStepAttempt,
    CodeExtractor,
    WebConsoleLogger,
    Code,
    CriticReview,
    JavaCodeExtractor,
    LocalObject,
    SaveLoadObject,
    Field,
    ObjectParser,
    enable_event_dumping, 
    set_global_budget_limit
)

from agentlib.lib import tools

AGENTPLANFILE = 'harness_analyzer.yaml'

# @tools.tool
# def read_two_funcs() -> str:
#     """
#     This function will read the code.
#     """
#     funca = read_code(COMMITA)
#     return funca
class HA_Output(SaveLoadObject):
    """
    This object describes the change in two code snippets.
    - key1: value_description.
    - key1: value_description.
    """

    seed: Any = Field(
        default="No", description="the input seed that will trigger the harness"
    )
    bytes_seed: str = Field(
        default="No", description="the script generated by the previous step"
    )
    seed_structure: str = Field(
        default="No", description="explain the seed structure and break it down for me"
    )
    source_func: str = Field(
        default="No",
        description="output the function that this harness is going to trigger",
    )


def generate_plan(model, pois_reason):
    # Create a plan for the agent to follow.
    steps_yaml = None
    with open(AGENTPLANFILE, 'r') as f:
        steps_yaml : List = yaml.safe_load(f).values()
    if not pois_reason:
        chosen_steps = [step for step in steps_yaml if step["name"] != "read_pois"]
    else:
        chosen_steps = steps_yaml
    _l.debug(f"chosen_steps is {chosen_steps}")
    assert chosen_steps is not None
    steps = list(map(
        lambda s: AgentPlanStep(llm_model=model,
                                name=s['name'],
                                description=s['description']),
        chosen_steps))
    # this would save it in json format.
    # hack - sometimes gpt changes the keys or adds spaces to json keynames. below is example of how to handle that
    # 'The output MUST be in the following JSON format and use the same keys OR I WILL DIE.\n' +
    #'{"equivalent": "Answer in Yes or No", "details": details_of_changes}'
    steps.append(AgentPlanStep(llm_model=model,
                               name="some_final_step",
                               description="Save data in a text format. ",
                               output_parser=ObjectParser(HA_Output, use_fallback=True)))
    PLAN = AgentPlan(steps=steps)
    return PLAN.save_copy()

class HarnessAnalyzer(PlanExecutor[str, str]):
    """
    This agent will follow the steps above.
    """

    __SYSTEM_PROMPT_TEMPLATE__ = "ha.system.j2"
    __USER_PROMPT_TEMPLATE__ = "ha.user.j2"
    __LLM_ARGS__ = {"temperature": 0}

    harness_code: Optional[str]
    source_and_traces: str
    jazzer_sanitizer_description: List
    pois_reason: Optional[str]

    def extract_step_attempt_context(
        self, step: AgentPlanStep, result: AgentResponse
    ) -> str:
        """
        Disable step summarization, and just use the last result from the LLM
        """
        return step.attempts[-1].result

    def extract_final_results(self) -> str:
        """
        Disable final output summarization and just use the last result from the LLM
        """
        steps = self.plan.get_past_steps()
        return steps[-1].attempts[-1].result

    def get_step_input_vars(self, step: AgentPlanStep) -> dict:
        # Template variables for the prompts
        return dict(
            **super().get_step_input_vars(step),
            hello="world",
            harness_code=self.harness_code,
            source_and_traces=self.source_and_traces,
            jazzer_sanitizer_description=self.jazzer_sanitizer_description,
            pois_reason=self.pois_reason
        )

    # def try_using_seed(self, script) -> Optional[CriticReview]:
    #     # Do whatever you need with the output here and then give feedback based on that
    #     # I am just going to decide by random
    #     py_script = script.split("\n")
    #     if "```" in script:
    #         py_script = py_script[1:-1]
    #     py_script = "\n".join(py_script)
    #     tmpdir = Path(tempfile.mkdtemp())
    #     tmp_py = tmpdir / "gen_seed.py"
    #     with open(tmp_py, "w") as f:
    #         f.write(py_script)
    #     p = subprocess.run(["python3", tmp_py], capture_output=True, text=True)
    #     if p.returncode != 0 or len(p.stderr) > 10:
    #         return CriticReview(
    #             success=False,
    #             feedback=f"That script has the following error \n {p.stderr}",
    #         )
    #     os.remove('output.bin')


    # def validate_step_result(
    #     self, step: AgentPlanStep, attempt: AgentPlanStepAttempt, result
    # ) -> bool:
    #     # Here we can perform validation on the result of the step
    #     # If we return False, the agent will retry the step with our feedback

    #     # This first example will take the llm output and pass it into some other part which uses that output and gives CriticFeedback
    #     if step.name == "generate_script":
    #         assert isinstance(result, str)
    #         res = self.try_using_seed(result)
    #         if not res:
    #             return True
    #         attempt.critic_review = res
    #         return False

    #     return super().validate_step_result(step, attempt, result)

    def on_step_success(self, step: AgentPlanStep, result):
        """
        This is just an example of how you could conditionally skip a step if you wanted.
        """
        if step.name == "should_we_skip_the_step":
            assert isinstance(result, str)
            if "true" in result.lower():
                # Skip over the next step
                self.plan.current_step += 1

        return super().on_step_success(step, result)


def convert_source_trace_to_prompt(source_and_traces: Dict) -> str:
    prompt = ""
    count = 1
    for source, traces in source_and_traces.items():
        prompt += f"The source code of function {count} is: \n {source}\n"
        prompt += f"The lines of codes that are on the taint analysis traces are: \n"
        for line in traces:
            prompt += f"{line}\n"
        count += 1
    prompt += f"The sink node is {line}\n"
    return prompt


def harness_agent(
    agent_path,
    harness_code: str,
    source_and_traces: str,
    jazzer_sanitizer_description: List,
    model: str,
    pois_reason: str = None
):
    # os.makedirs('/shared/quickseed-agentlib-cost', exist_ok=True)
    enable_event_dumping('/shared/quickseed-agentlib-cost') # somewhere in shared
    set_global_budget_limit(
        price_in_dollars=5,
        exit_on_over_budget=True
    )
    os.chdir(os.path.dirname(__file__))
    plan = generate_plan(model, pois_reason)
    agent: HarnessAnalyzer = HarnessAnalyzer.reload_id_from_file_or_new(
        agent_path,
        goal="generate interesting seeds",
        plan=plan,
        harness_code=harness_code,
        source_and_traces=source_and_traces,
        jazzer_sanitizer_description=jazzer_sanitizer_description,
        pois_reason=pois_reason
    )

    agent.use_web_logging_config()

    agent.warn(f"========== Agents plan ==========\n")
    _l.debug(agent)
    _l.debug(agent.plan)

    agent.warn(f"========== Running agent ==========\n")

    res = agent.invoke()
    script = res.bytes_seed.split("\n")
    if "```" in res.bytes_seed:
        script = script[1:-1]
    _l.debug(f"The script dumping in gen_seed.py is {script}")
    if "No " in script[0]:
        return None
    script = "\n".join(script)
    
    tmpdir = Path(tempfile.mkdtemp())
    _l.info(f"the files is saved to {tmpdir}")

    tmp_py = tmpdir / "gen_seed.py"
    tmp_bin = tmpdir / "output.bin"
    with open(tmp_py, "w") as f:
        f.write(script)
    with WorkDirContext(tmpdir):
        try:
            p = subprocess.run(["python3", tmp_py], capture_output=True, text=True, errors = "ignore")
            if p.returncode != 0:
                _l.debug(f"{p.stderr}")
        except Exception as e:
            _l.error(f"error occured {e} when generating seeds")
            return None
    if not tmp_bin.exists():
        return None

    with open(tmp_bin, "rb") as f:
        return f.read()

  
